{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36ff73ee-c214-4c8d-91bd-2ec6cd26c205",
   "metadata": {},
   "source": [
    "___\n",
    "# __OCR NLP Project__\n",
    "### Mercedes Wu\n",
    "##### Time limit: 4 hrs\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4be0c3-d4c8-440e-811e-b28d893bec95",
   "metadata": {},
   "source": [
    "___\n",
    "## __Getting OCR Receipt Data from: https://github.com/clovaai/cord__\n",
    "- data is stored in json format with xy coordinates\n",
    "- train size - 800 images\n",
    "- test size - 100 images\n",
    "- including some sample images in data folder\n",
    "- data does not contain personal information\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a15d902-a9f6-493d-b6e2-41d904203dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38274b1b-3567-4cb2-b4dc-2e1a97e8e8da",
   "metadata": {},
   "source": [
    "___\n",
    "## __Data Exploration of Dataset__\n",
    "- looking at a test image and it's respective json data to get a feel for the data\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc5132c-0467-41dd-9aa5-ae1bac6cdd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = io.imread('./data/receipt_ocr/images/train/receipt_00797.png')\n",
    "fig,ax = plt.subplots(figsize=(100,200))\n",
    "ax = plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27cf4fc-7a72-478b-99c9-04a4d920b324",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = './data/receipt_ocr/json/train/'\n",
    "with open(f'{folder}receipt_00797.json') as f:\n",
    "    d = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7c214b-d9ed-42bb-b41e-92f301c6026a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a624716-96dd-44a5-a93c-fa7deba85e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d['valid_line'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d8db54-22c3-4056-ac61-23c0eb2dc4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "d['dontcare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37971e89-8f86-418c-a974-a139e2475820",
   "metadata": {},
   "outputs": [],
   "source": [
    "d['meta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff206e7e-89ff-45ff-8b34-e629fd55c481",
   "metadata": {},
   "outputs": [],
   "source": [
    "d['roi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6ad407-b482-4c58-a3a7-0a636a79ce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d['repeating_symbol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec68bbe-b08f-4f22-85cc-7c74a0cc12ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "d['valid_line'][0]['words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd17da36-4241-4a8c-b7bc-4a190916273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d['valid_line'][1]['words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac996741-6835-47aa-be83-cec5f5423626",
   "metadata": {},
   "outputs": [],
   "source": [
    "d['valid_line'][0]['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de42ef2-ef29-4f4c-a871-45f186f95b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d['valid_line'][0]['group_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2ef1c6-6527-416d-87b6-e7cc670fc2cd",
   "metadata": {},
   "source": [
    "___\n",
    "__notes so far__\n",
    "- valid line gives the most useful information\n",
    "- can ignore dont care, meta, and ROI for now but in real life data it might not be this simple\n",
    "- quad gives boundry box of OCR scan\n",
    "- category is the correct label for the ocr text, we can use this as a target\n",
    "- group_id seems to be a numerical key of the category\n",
    "- not sure what rowid refers to yet <br>\n",
    "\n",
    "__ideas__\n",
    "- would be nice to get this into a dataframe format\n",
    "- can use the quad data to help group together certain items for the menu \n",
    "    - e.g. \"1 Grilled Baby Potato (R\"\n",
    "- whether the text is a number or a string can also give us valuable information\n",
    "- will probably need to use regex or heuristic based filtering to get rid of some noise \n",
    "    - e.g. \"(R\"\n",
    "- repeating symbol would be useful to help segment image but for the sake of time/complexity we will ignore it for now\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb84964-2233-4927-8257-15697f44433f",
   "metadata": {},
   "source": [
    "___\n",
    "## __Creating a Training Dataset for Modeling__\n",
    "- transforming json data in \"valid_line\" to dataframe\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941018bd-4212-4d08-a1db-9127d1cea406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after some initial testing, i cant find a super easy solution\n",
    "df = pd.DataFrame.from_dict(d['valid_line'], orient='columns')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd23051-5440-424e-8f9f-765bdd688c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['words'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835476e3-fc77-4729-8d8a-f6f57d4009ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to breakdown words column, going to use lambda function but there is most likely room for improvement\n",
    "# first breaking down the quad to coordinate values\n",
    "df['quad'] = df['words'].map(lambda x: x[0]['quad'])\n",
    "df['x1'] = df['quad'].map(lambda x: x['x1'])\n",
    "df['x2'] = df['quad'].map(lambda x: x['x2'])\n",
    "df['x3'] = df['quad'].map(lambda x: x['x3'])\n",
    "df['x4'] = df['quad'].map(lambda x: x['x4'])\n",
    "df['y1'] = df['quad'].map(lambda x: x['y1'])\n",
    "df['y2'] = df['quad'].map(lambda x: x['y2'])\n",
    "df['y3'] = df['quad'].map(lambda x: x['y3'])\n",
    "df['y4'] = df['quad'].map(lambda x: x['y4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829508e5-c7cb-48bb-b2f9-ad378c2a5173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting out text to a column\n",
    "df['text'] = df['words'].map(lambda x: x[0]['text'])\n",
    "# splitting out iskey&rowid to get a better idea, might need to not use it as a feature to be fair though\n",
    "df['row_id'] = df['words'].map(lambda x: x[0]['row_id'])\n",
    "df['is_key'] = df['words'].map(lambda x: x[0]['is_key'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7d7c25-7e5b-485d-8fa6-3dc1fd2b5db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7470dd78-4513-4509-9905-0e9b663a66c2",
   "metadata": {},
   "source": [
    "___\n",
    "__notes__\n",
    "- looks like rowid calculates based on the quad if the items are on the same line\n",
    "- techniques for this include random sample consensus (RANSAC)\n",
    "     - we should try implementing this but due to time constraints let's see the results of initial modeling techniques\n",
    "___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02b0b45-f102-408b-8ebf-0c8da43b06b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting above code into a function to run over all the json images\n",
    "def json_to_df_helper(d):\n",
    "    df = pd.DataFrame.from_dict(d['valid_line'], orient='columns')\n",
    "    # need to breakdown words column, going to use lambda function but there is most likely room for improvement\n",
    "    # first breaking down the quad to coordinate values\n",
    "    df['quad'] = df['words'].map(lambda x: x[0]['quad'])\n",
    "    df['x1'] = df['quad'].map(lambda x: x['x1'])\n",
    "    df['x2'] = df['quad'].map(lambda x: x['x2'])\n",
    "    df['x3'] = df['quad'].map(lambda x: x['x3'])\n",
    "    df['x4'] = df['quad'].map(lambda x: x['x4'])\n",
    "    df['y1'] = df['quad'].map(lambda x: x['y1'])\n",
    "    df['y2'] = df['quad'].map(lambda x: x['y2'])\n",
    "    df['y3'] = df['quad'].map(lambda x: x['y3'])\n",
    "    df['y4'] = df['quad'].map(lambda x: x['y4'])\n",
    "    # splitting out text to a column\n",
    "    df['text'] = df['words'].map(lambda x: x[0]['text'])\n",
    "    # splitting out iskey&rowid to get a better idea, might need to not use it as a feature to be fair though\n",
    "    df['row_id'] = df['words'].map(lambda x: x[0]['row_id'])\n",
    "    df['is_key'] = df['words'].map(lambda x: x[0]['is_key'])\n",
    "    \n",
    "    # filtering down to training features\n",
    "    return df[['x1', 'x2', 'x3', 'x4', 'y1', 'y2', 'y3', 'y4', 'text', 'row_id', 'is_key', 'category', 'group_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69309cf3-65d1-415c-b225-0761804d225c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating train and test dataframes\n",
    "def dataset_generator(path_to_jsonfiles):\n",
    "    dfs = []\n",
    "    for file in os.listdir(path_to_jsonfiles):\n",
    "        full_filename = \"%s/%s\" % (path_to_jsonfiles, file)\n",
    "        with open(full_filename,'r') as f:\n",
    "            d = json.load(f)\n",
    "        dfs.append(json_to_df_helper(d))\n",
    "    return pd.concat(dfs, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dab4c1a-48f9-438d-941b-c01056a643d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dataset_generator('./data/receipt_ocr/json/train/')\n",
    "test_df = dataset_generator('./data/receipt_ocr/json/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f036d478-d5fc-4fa4-b708-4d52608ce4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87c30b0-521e-4138-8567-a30f302b4549",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4389ec-a7f7-481c-87ec-bc68b6a7c9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets look at the count of values for each category first as a quick check to see if there are any class imbalances\n",
    "count_train_gb = train_df[['category', 'text']].groupby('category').count().reset_index()\n",
    "ax = count_train_gb.plot.bar(x='category', y='text', title='Count Classes in Training Data', figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298ae0b3-6764-4bbb-b04f-59ff5c2c9188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets look at the count of values for each category first as a quick check to see if there are any class imbalances\n",
    "count_test_gb = test_df[['category', 'text']].groupby('category').count().reset_index()\n",
    "ax = count_test_gb.plot.bar(x='category', y='text', title='Count Classes in Testing Data', figsize=(20,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320b9ac0-4fde-4197-a024-780b47065a24",
   "metadata": {},
   "source": [
    "___\n",
    "__Feature Engineering__\n",
    "- to simplify the classification task for now, we can:\n",
    "    - drop categories that have less than 100 datapoints in the training data \n",
    "        - we can address the the dropped classes later\n",
    "    - make sure the classes between testing and training sets are the same\n",
    "        - this doesnt mimic a real word scenario but will still give us an idea of how well our models do in ideal situations\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116fbd80-c1d5-46fa-8d7e-2ea9bf888997",
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_categories = list(count_train_gb[count_train_gb['text']>100]['category'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a2412c-1a23-4367-8157-6f7765491109",
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fe2967-8353-4b60-95fa-e5901adfa011",
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_train_df = train_df[train_df['category'].isin(filt_categories)].copy()\n",
    "filt_test_df = test_df[test_df['category'].isin(filt_categories)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdf5a39-8a43-4fae-8406-b72e8003894b",
   "metadata": {},
   "source": [
    "___\n",
    "TODO 11/29/21:\n",
    "- add some simple feature generation like:\n",
    "    - length string\n",
    "    - is it a str, int, float\n",
    "    - some ranges that items would cost\n",
    "        - unlikely to find an item > $10,000 dollars\n",
    "Note:\n",
    "- looks like the reciepts can be from different countries, need to account for the fact that some countries use , to separate out change\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30120ea2-6fb9-4fb7-ae69-b718249765b5",
   "metadata": {},
   "source": [
    "___\n",
    "## __Modeling__\n",
    "- is this a supervised machine learning problem?\n",
    "    - i.e. we can leverage past labeled data for inferencing?\n",
    "    - this way we can utlize techniques that take advangtage of the labeled dataset\n",
    "- is this a unsupervised machine learning problem?\n",
    "    - can utilize:\n",
    "        - business logic\n",
    "        - positional and linguistic cues\n",
    "        - some heuristics on receipts to group unlabeled data \n",
    "        - clustering techniques based on position\n",
    "- given the current data, the best choice may be a combination of the two\n",
    "    - we can use the training data to get us closer to the the preferrered or custom categories then use heuristics/decision trees to break it down further\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015c5622-0c14-4fbd-a647-0ea67597d240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizing text column\n",
    "vectorizer = CountVectorizer()\n",
    "# term frequency inverse document frequency transformer\n",
    "tfidf_transformer = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9339ceb-7e57-4870-812b-7928c01e8b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizing and tfidf transforming training data\n",
    "X_train_counts = vectorizer.fit_transform(filt_train_df['text'])\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "y_train = filt_train_df['category']\n",
    "# vectorizing and tfidf transforming testing data\n",
    "X_test_counts = vectorizer.fit_transform(filt_test_df['text'])\n",
    "X_test_tfidf = tfidf_transformer.fit_transform(X_test_counts)\n",
    "y_test = filt_test_df['category']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ab9979-114d-418e-acd4-1e00a7667588",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8c36e3-7167-4df8-9d9e-d9823dde1ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a804e5-8e18-4b16-a23f-f87c7bc3890d",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(list(y_train.unique())) - set(list(y_test.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c808a76a-05b2-4a57-808d-76831a05c41c",
   "metadata": {},
   "source": [
    "___\n",
    "Note:\n",
    "- we need the number of columns to match for training and testing data in order to predict\n",
    "- can use select k best to find the more important features\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0dd1ab-a635-498f-8dd0-62f874db19c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2db475d-a50e-4199-ac65-b6e8637a5de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we would need to use SelectKBest to make sure each set of data had the same number of columns\n",
    "X_train_tfidf_new = SelectKBest(chi2, k=405).fit_transform(X_train_tfidf, y_train)\n",
    "X_test_tfidf_new = SelectKBest(chi2, k=405).fit_transform(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18034a5-9b89-4e30-9987-f27f6b56314e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting naive bayes multi classifier\n",
    "clf = MultinomialNB().fit(X_train_tfidf_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ad1a01-8cf3-4d85-9341-05128e95896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_test_df['NB_pred'] = clf.predict(X_test_tfidf_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6077b6c-e7ab-48b2-8995-7b876974671a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_test_df['NB_correct_prediction'] = np.where(filt_test_df['category'] == filt_test_df['NB_pred'], 'yes', 'no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e178cc6-cf11-4a62-9761-f7e3b4c7c638",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_results = filt_test_df['NB_correct_prediction'].value_counts()\n",
    "nb_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26cfacc-ce41-4dd6-a7da-599bb5ab2504",
   "metadata": {},
   "source": [
    "___\n",
    "Note:\n",
    "- initial results with Naive Bayes Classifier doesn't seem great\n",
    "- can test if a different model and adding will a different model and kfold (due to low data points for some classes) cross validation will improve the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4e3d25-6b18-4739-8c37-f1ea7304a79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting support vector class weight to balanced to automatically adjust weights inversely proportional to class frequencies\n",
    "model = LinearSVC(class_weight=\"balanced\", dual=False, tol=1e-2, max_iter=1e5)\n",
    "kf = KFold(n_splits=3)\n",
    "cclf = CalibratedClassifierCV(base_estimator=model, cv=kf)\n",
    "cclf.fit(X_train_tfidf_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4509c1-a93e-4bef-912e-fa86e08a61d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filt_test_df['SCV_pred_w_CCCV'] = cclf.predict(X_test_tfidf_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2d7f27-d08f-4080-bd86-35f5149ae29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_test_df['SCV_pred_w_CCCV_correct_prediction'] = np.where(filt_test_df['category'] == filt_test_df['SCV_pred_w_CCCV'], 'yes', 'no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b815a67b-0225-400a-8cc6-0aed8d5e4a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scv_results = filt_test_df['SCV_pred_w_CCCV_correct_prediction'].value_counts()\n",
    "scv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7d2f14-723b-43a4-9c8b-2b29a581670d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat([nb_results, scv_results], axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705f2e8c-6da1-4832-b059-07b00a75112d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['accuracy'] = results['yes'] / (results['no']+results['yes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a2943a-b9f7-4fa4-97fe-8a21d89e0387",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae90554-c488-4978-b92c-5675ecfa594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = results.plot.bar(x='index', y='accuracy', figsize=(20,10), color={'orange':'SCV_pred_w_CCCV_correct_prediction', 'blue':'NB_correct_prediction'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0e4e52-aa6e-45ca-8e36-c727992faf81",
   "metadata": {},
   "source": [
    "___\n",
    "## __Conclusion__\n",
    "- This project was fun and a nice introduction to how computer vision and NLP can be related!\n",
    "- With more time, I would have liked to:\n",
    "    - explore the modeling side more, expecially the unsupervised approach and using the OCR x,y coordinates as hints as to what a field could be\n",
    "    - use more feature generation especially with the number fields\n",
    "        - e.g. date formatting, number limits, integers for quantiy vs floats for prices'\n",
    "- I believe using a combination of both supervised and unsupervised learning would make the model development process go faster\n",
    "    - we could use the any availabe training data to help give us an idea of where certain categories like menu usually lie in a receipt\n",
    "        - I think this would look nice visualized as a heatmap\n",
    "___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77432b1c-9ef0-4dc5-957c-fa6769fbda70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc55849-9345-48e2-a5c3-7f2fe3aa1db8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
